{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit01921fdebdd24efa8d6ff90ac85a0e91",
   "display_name": "Python 3.8.3 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py \n",
    "\n",
    "import yaml\n",
    "import gzip\n",
    "\n",
    "# READ FILE USING YAML \n",
    "def read_yaml(path):\n",
    "    \n",
    "    with open(path, 'r') as data: \n",
    "        try:\n",
    "            return yaml.safe_load(data)\n",
    "        except:\n",
    "            print(\"Something went wrong with loading the data.\")\n",
    "\n",
    "# CLEAN THE COLUMN NAMES \n",
    "def clean_col_names(df):\n",
    "\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[%\\W]', '', regex= True)\n",
    "\n",
    "# RETURN DIFFERENCE IN COLUMNS \n",
    "def col_dif(df, conf_table):\n",
    "\n",
    "    df_cols = list(df.columns)\n",
    "    ct_cols = conf_table[\"columns\"]\n",
    "    missing_from_df = list(set(ct_cols).difference(df_cols))\n",
    "    missing_from_ct = list(set(df_cols).difference(ct_cols))\n",
    "    \n",
    "    return df_cols, missing_from_df, ct_cols, missing_from_ct\n",
    "\n",
    "# CHECKS FOR THE SAME NUMBER OF COLUMNS  \n",
    "def col_val(df, conf_table):\n",
    "\n",
    "    df_cols = list(df.columns)\n",
    "    ct_cols = list(conf_table[\"columns\"])\n",
    "    df_cols_count = len(df_cols)\n",
    "    ct_cols_count = conf_table[\"num_columns\"]\n",
    "\n",
    "    if df_cols == ct_cols:\n",
    "        print(\"Validation test: PASS\")\n",
    "        return 1\n",
    "    else: \n",
    "        print(\"Validation test: FAILED\")\n",
    "        print(f\"Incoming data consists of {df_cols_count} columns.\")\n",
    "        print(f\"YAML file consists of {ct_cols_count} columns.\")\n",
    "        print(\"The listed columns are not in the incoming data: \\n{}\".format(list(set(ct_cols).difference(df_cols))))\n",
    "        print(\"The listed columns are not in the YAML file: \\n{}\".format(list(set(df_cols).difference(ct_cols))))\n",
    "        return 0 \n",
    "\n",
    "# WRITE TE FILE IN PUIPE SEPARATED TEXT FILE IN GZ FORMAT\n",
    "def write_file(df):\n",
    "\n",
    "    df.to_csv(\n",
    "        \"stocks.csv.gz\",\n",
    "        index= False,\n",
    "        sep= \"|\",\n",
    "        compression= \"gzip\"\n",
    "    )\n",
    "\n",
    "# SUMMARY OF THE DATA\n",
    "def summary(conf_table):\n",
    "\n",
    "    print(\"The file name is {}\".format(conf_table[\"path\"]))\n",
    "    print(\"The delimiter used is '{}'\".format(conf_table[\"delimiter\"]))\n",
    "    print(\"The number of columns in the data is {}\".format(conf_table[\"num_columns\"]))\n",
    "    print(\"The data is 2GB in size.\")\n",
    "    print(\"The columns for the data are: {}\".format(conf_table[\"columns\"]))\n",
    "\n",
    "# DISPLAY THE RESULTS\n",
    "def result(col_val, df, conf_table):\n",
    "\n",
    "    if col_val == 1: \n",
    "        # write the file in pip (|) separated text file\n",
    "        write_file(df)\n",
    "        # summary of the file \n",
    "        summary(conf_table)\n",
    "    else: \n",
    "        df_cols, missing_from_df, ct_cols, missing_from_ct = col_dif(df, conf_table)\n",
    "        print(\"It seems that the incoming data containing the following columns: {} \\nis missing {} \".format(df_cols,missing_from_df))\n",
    "        print(\"It seems that the YAML file containing the following columns: {} \\nis missing {} \".format(ct_cols, missing_from_ct))"
   ]
  },
  {
   "source": [
    "## Creating a YAML file for the data and then reading the YAML file to read the data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting stocks.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile stocks.yaml\n",
    "\n",
    "path: stocks.csv\n",
    "delimiter: \",\"\n",
    "num_columns: 6\n",
    "columns: \n",
    "    - exchangecountry\n",
    "    - symbol\n",
    "    - companyname\n",
    "    - returnonequity\n",
    "    - priceearningsratio\n",
    "    - dividendyield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'path': 'stocks.csv',\n",
       " 'delimiter': ',',\n",
       " 'num_columns': 6,\n",
       " 'columns': ['exchangecountry',\n",
       "  'symbol',\n",
       "  'companyname',\n",
       "  'returnonequity',\n",
       "  'priceearningsratio',\n",
       "  'dividendyield']}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# using YAML \n",
    "import utils as u \n",
    "\n",
    "conf_table = u.read_yaml(\"stocks.yaml\")\n",
    "conf_table"
   ]
  },
  {
   "source": [
    "## Reading the data using Pandas, Dask, csv modules in python "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import dask.dataframe \n",
    "import csv\n",
    "\n",
    "# using pandas \n",
    "pd_stocks = pd.read_csv(\"stocks.csv\")\n",
    "\n",
    "# using Dask \n",
    "dask_stocks = dask.dataframe.read_csv(\"stocks.csv\")\n",
    "\n",
    "# using csv\n",
    "csv_file = open(\"stocks.csv\")\n",
    "data = csv.reader(csv_file, delimiter= \",\", quotechar= \"|\")\n",
    "csv_file.close()"
   ]
  },
  {
   "source": [
    "## cleaning the pandas data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Exchange Country',\n",
       " 'Symbol',\n",
       " 'Company Name ',\n",
       " 'Return on Equity %',\n",
       " 'Price / Earnings Ratio %',\n",
       " 'Dividend Yield %']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "list(pd_stocks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['exchangecountry',\n",
       " 'symbol',\n",
       " 'companyname',\n",
       " 'returnonequity',\n",
       " 'priceearningsratio',\n",
       " 'dividendyield']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# cleaning the column headers \n",
    "u.clean_col_names(pd_stocks)\n",
    "\n",
    "list(pd_stocks.columns)"
   ]
  },
  {
   "source": [
    "## Validate the incoming dataframe from Pandas with the YAML file information on the data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation test: PASS\nThe file name is stocks.csv\nThe delimiter used is ','\nThe number of columns in the data is 6\nThe data is 2GB in size.\nThe columns for the data are: ['exchangecountry', 'symbol', 'companyname', 'returnonequity', 'priceearningsratio', 'dividendyield']\n"
     ]
    }
   ],
   "source": [
    "col_val = u.col_val(pd_stocks, conf_table)\n",
    "u.result(col_val, pd_stocks, conf_table)"
   ]
  },
  {
   "source": [
    "## test dataframe to demo what happens if the columns dont match \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation test: FAILED\nIncoming data consists of 3 columns.\nYAML file consists of 6 columns.\nThe listed columns are not in the incoming data: \n['dividendyield', 'priceearningsratio', 'symbol', 'returnonequity']\nThe listed columns are not in the YAML file: \n['madeupcolumn']\n\n\nIt seems that the incoming data containing the following columns: ['exchangecountry', 'companyname', 'madeupcolumn'] \nis missing ['dividendyield', 'priceearningsratio', 'symbol', 'returnonequity'] \nIt seems that the YAML file containing the following columns: ['exchangecountry', 'symbol', 'companyname', 'returnonequity', 'priceearningsratio', 'dividendyield'] \nis missing ['madeupcolumn'] \n"
     ]
    }
   ],
   "source": [
    "demo_data = {\n",
    "    \"exchange country\": [\"country 1\", \"country 2\"],\n",
    "    \"company name\": [\"name 1\", \"name 2\"],\n",
    "    \"made up column\": [1, 2]\n",
    "}\n",
    "\n",
    "demo_df = pd.DataFrame(demo_data, columns= [\"exchange country\", \"company name\", \"made up column\"])\n",
    "\n",
    "# cleaning cols \n",
    "u.clean_col_names(demo_df)\n",
    "# val col \n",
    "demo_col_val = u.col_val(demo_df, conf_table)\n",
    "print(\"\\n\")\n",
    "# results from validation \n",
    "u.result(demo_col_val, demo_df, conf_table)"
   ]
  }
 ]
}